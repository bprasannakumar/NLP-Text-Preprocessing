{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Stemming is the process of reducing inflected or derived words to their base form or root form, called as stem, by chopping off or replacing the suffixes of the words.  The resulting stem may not be identical to the  morphological root of the word.\n",
    "\n",
    "Examples:\n",
    "Rule:            Word         Stem Word\n",
    "SSES -> SS       possesses  -> posses     \n",
    "IES  ->  I       pennies    -> penni\n",
    "SS   -> SS       caress     -> caress\n",
    "S    ->          cats       -> cat\n",
    "\n",
    "If we apply stemming on a document corpus, it will convert many inflected/derived form of a word into its root word and all those derived words will be treated as a single word when we construct the vocabulary from the given corpus. Hence, it will considerably decrease the size of the vocabulary.\n",
    "\n",
    "Let's use NLTK and look at few examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = \"learning learns learned learnt caresses pennies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_tokens = []\n",
    "for token in tokens:\n",
    "    stemmed_token = ps.stem(token)\n",
    "    stemmed_tokens.append(stemmed_token)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['learn', 'learn', 'learn', 'learnt', 'caress', 'penni']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at example and see how stemming helps us to reduce the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['they are watching movies', 'they all watched movies', 'he always watches that movie']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer2 = TreebankWordTokenizer()\n",
    "ps2 = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "all_stemmed_tokens = []\n",
    "for doc in corpus:\n",
    "    tokens = tokenizer2.tokenize(doc)\n",
    "    stemmed_tokens = []\n",
    "    for token in tokens:\n",
    "        st = ps2.stem(token)\n",
    "        stemmed_tokens.append(st)\n",
    "        if st not in vocabulary:\n",
    "            vocabulary.append(st)\n",
    "    all_stemmed_tokens.append(stemmed_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['they', 'are', 'watch', 'movi'],\n",
       " ['they', 'all', 'watch', 'movi'],\n",
       " ['he', 'alway', 'watch', 'that', 'movi']]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_stemmed_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['they', 'are', 'watch', 'movi', 'all', 'he', 'alway', 'that']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above corpus, if we do not use stemming, our vocab size will be 13, whereas after stemming our vocabulary size is 8\n",
    "# In a large corpus of data, this is very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatization is the process of reducing inflected or derived words to their base form or root form, which is similar to dictionary form (called as lemma), using morphological analysis. The lemma is usually identical to the morphological root of the word, which is used in dictionary.\n",
    "\n",
    "If we apply lemmatization on a document corpus, this will convert many inflected/derived form of a word into its root word and all those derived words will be treated as a single word when we construct the vocabulary from the given corpus. Hence, it will considerably decrease the size of the vocabulary, especially when we have a huge corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\prasa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = \"learning learns learned learnt caresses pennies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer3 = TreebankWordTokenizer()\n",
    "lm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm_tokens = []\n",
    "for token in tokenizer3.tokenize(doc2):\n",
    "    l_token = lm.lemmatize(token)\n",
    "    lemm_tokens.append(l_token)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['learning', 'learns', 'learned', 'learnt', 'caress', 'penny']\n"
     ]
    }
   ],
   "source": [
    "print(lemm_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:  \n",
    "#### If we stem the word pennies, it is converted to penni whereas if we lemmatize the same word pennies, it is converted to penny, which is it dictionary form.\n",
    "#### Again, whether to use stemming or lemmatization depends on the problem.  We need to use both and see which one works well for our problem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
